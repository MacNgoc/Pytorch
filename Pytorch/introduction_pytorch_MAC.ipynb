{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de tenseur \n",
    "\n",
    "Pytorch (et tensorflow) utilisent des \"tenseurs\" pour stocker des données. C'est l'équivalent des ndarray de numpy et fonctionnent de manière similaire avec quelques fonctionalités en plus. Une des choses très intéressantes avec Pytorch est sa forte compatibilité avec numpy. \n",
    "\n",
    "Avec la méthode torch.tensor créer un vecteur contenant les valeurs [-1, 2, 3, 5] et le stocker dans la variable t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher son type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([-1, 2, 3, 5])\n",
    "t.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer 2 * t, qu'est ce que ça fait ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2,  4,  6, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un tensor avec les valeurs [-1, 2.2, 3.3] et le stocker dans la variable t2. Afficher son type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([-1, 2.2, 3.3])\n",
    "t2.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher la méthode permettant de convertir un tenseur float en tenseur de type Long et convertir t2 en type Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = t.float()\n",
    "t3.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4 = t2.long()\n",
    "t4.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une matrice aléatoire de taille 3, 3 avec la fonction numpy.random.randn et créer un tenseur pytorch à partir du tableau numpy et le stocker dans la variabne **A**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7757, 0.5414, 0.4888],\n",
       "        [0.9445, 0.9740, 0.5185],\n",
       "        [0.9337, 0.8630, 0.2235]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(3,3)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation et fonctions sur les tenseurs\n",
    "\n",
    "Comme numpy, pytorch possède toutes les fonctions mathématiques standard. \n",
    "\n",
    "a l'aide de la méthode torch.cos, calculer le cosinus du tenseur A précédent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7140, 0.8570, 0.8829],\n",
       "        [0.5862, 0.5620, 0.8685],\n",
       "        [0.5949, 0.6502, 0.9751]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer exp de la même manière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1720, 1.7184, 1.6304],\n",
       "        [2.5714, 2.6486, 1.6796],\n",
       "        [2.5439, 2.3703, 1.2504]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la somme des valeurs du tensor A et la moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2631)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6959)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Différentiation automatique\n",
    "\n",
    "Pytorch permet de faire des choses très pratiques : calculer les dérivée partielles d'expression utilisant des tenseurs. \n",
    "\n",
    "Avec la fonction torch.tensor, créer un tenseur à une dimension contenant la valeur -1;0 et la stocker dans la variable **t**\n",
    "\n",
    "Il faudra spécifier la valeur requires_grad = True en créant le tenseur\n",
    "\n",
    "Calculer $ exp(-t^2) $ et stocker le resultat dans la variable **z**\n",
    "\n",
    "appeler la méthode .backward sur le tenseur z\n",
    "\n",
    "vous pourrez ainsi récupérer le gradient de z par rapport à t dans la variable t. Le stocker dans la variable grad_t et l'afficher\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7358])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([-1.], requires_grad = True)\n",
    "h = -t**2\n",
    "z = torch.exp(h)\n",
    "z.backward()\n",
    "t.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Gradient of function $y = f(x) \\,  \\mbox{or}  \\, y = exp(h), h = -t^2, t = (t_1, t_2, t_3) $ respect to t is a Jacobien matrix J, so, for a vector v = (v_1, v_2, v_3), we can compute $ v^T.J $\n",
    "- Ref : https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, -0.0000, 0.7358])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([-1., 0., 1.], requires_grad = True)\n",
    "h = -t2**2\n",
    "z = torch.exp(h)\n",
    "#z.backward()\n",
    "# t2.grad \n",
    "# --> error\n",
    "v = torch.tensor([0., 1., -1.])\n",
    "z.backward(v)\n",
    "print(t2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression linéaire avec Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice on va faire une mini regression linéaire\n",
    "\n",
    "Créer un tensor **theta** contenant $\\theta_0 = -1$ et $\\theta_1 = 0.5 $ en activant les gradient. \n",
    "\n",
    "Créer un tensor X avec les valeurs 1, 2, 3, 4 sans gradient\n",
    "\n",
    "Créer un tensor y avec les valeurs 2, 4, 6, 8 sans gradient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.tensor([-1., 0.5], requires_grad = True)\n",
    "X = torch.tensor([1.,2.,3.,4.])\n",
    "y = torch.tensor([2., 4., 6., 8.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer $ \\hat{y}  = \\theta_0 + \\theta_1 * x$  et le stocker dans la variable **y_pred**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = theta[0] + theta[1]*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5000,  0.0000,  0.5000,  1.0000], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la MSE entre les prédictions et les labels et le stocker dans la variable **mse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.3750, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = torch.mean((y_pred - y)**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utiliser la méthode  backward sur **mse** et afficher le gradient par rapport à $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -9.5000, -27.5000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse.backward()\n",
    "theta.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le premier vrai modèle\n",
    "\n",
    "Jusqu'à présent on a manipulé les tenseurs à la main. Mais pour créer des modèles en Pytorch il faut créer des classes qui hérite de nn.Module. \n",
    "\n",
    "Compléter la classe LinearRegression suivante qui permet d'implémenter une régression linéaire qui utilise une seule variable X pour prédire Y. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(1,1)# input_dim and output_dim\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement d'un modèle. \n",
    "\n",
    "Contrairement à Keras, Pytorch ne fournit pas de methode .fit sur les modèles. Il faut faire sa procédure d'entraînement soi même, ce qui a l'avantage de proposer plus de souplesses. Pour pouvoir effectuer l'entraînement il faut plusieurs ingrédients: \n",
    "\n",
    "- un optimiser \n",
    "- une fonction de loss\n",
    "- les données\n",
    "- le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une instance de votre modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant permet de charger un csv comme dataset. L'adapter pour qu'il marche avec votre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_reg.csv')\n",
    "x = torch.tensor(df[\"x\"].values).float().view(7,1)# need to reshape tensor\n",
    "y = torch.tensor(df[\" y\"].values).float().view(7,1)# need to reshape tensor\n",
    "train = data_utils.TensorDataset(x,y)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=7, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une instance de MSELoss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = nn.MSELoss(reduction='mean')\n",
    "#loss = loss_fn(train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une instance de l'optimiser SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.005\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compléter le code suivant qui permet de faire l'entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "prediction tensor([[ 0.0094],\n",
      "        [ 0.2390],\n",
      "        [ 0.4687],\n",
      "        [-0.2202],\n",
      "        [ 0.0094],\n",
      "        [-1.3684],\n",
      "        [-1.4143]], grad_fn=<AddmmBackward>)\n",
      "loss 2.735759973526001\n",
      "iteration 1\n",
      "prediction tensor([[ 0.0376],\n",
      "        [ 0.2745],\n",
      "        [ 0.5114],\n",
      "        [-0.1992],\n",
      "        [ 0.0376],\n",
      "        [-1.3836],\n",
      "        [-1.4310]], grad_fn=<AddmmBackward>)\n",
      "loss 2.656813859939575\n",
      "iteration 2\n",
      "prediction tensor([[ 0.0653],\n",
      "        [ 0.3092],\n",
      "        [ 0.5532],\n",
      "        [-0.1786],\n",
      "        [ 0.0653],\n",
      "        [-1.3983],\n",
      "        [-1.4471]], grad_fn=<AddmmBackward>)\n",
      "loss 2.581012010574341\n",
      "iteration 3\n",
      "prediction tensor([[ 0.0924],\n",
      "        [ 0.3432],\n",
      "        [ 0.5940],\n",
      "        [-0.1584],\n",
      "        [ 0.0924],\n",
      "        [-1.4123],\n",
      "        [-1.4625]], grad_fn=<AddmmBackward>)\n",
      "loss 2.5082154273986816\n",
      "iteration 4\n",
      "prediction tensor([[ 0.1190],\n",
      "        [ 0.3765],\n",
      "        [ 0.6339],\n",
      "        [-0.1385],\n",
      "        [ 0.1190],\n",
      "        [-1.4258],\n",
      "        [-1.4773]], grad_fn=<AddmmBackward>)\n",
      "loss 2.4382898807525635\n",
      "iteration 5\n",
      "prediction tensor([[ 0.1450],\n",
      "        [ 0.4090],\n",
      "        [ 0.6730],\n",
      "        [-0.1189],\n",
      "        [ 0.1450],\n",
      "        [-1.4388],\n",
      "        [-1.4916]], grad_fn=<AddmmBackward>)\n",
      "loss 2.371108293533325\n",
      "iteration 6\n",
      "prediction tensor([[ 0.1706],\n",
      "        [ 0.4409],\n",
      "        [ 0.7112],\n",
      "        [-0.0997],\n",
      "        [ 0.1706],\n",
      "        [-1.4512],\n",
      "        [-1.5053]], grad_fn=<AddmmBackward>)\n",
      "loss 2.306549549102783\n",
      "iteration 7\n",
      "prediction tensor([[ 0.1956],\n",
      "        [ 0.4721],\n",
      "        [ 0.7485],\n",
      "        [-0.0808],\n",
      "        [ 0.1956],\n",
      "        [-1.4631],\n",
      "        [-1.5184]], grad_fn=<AddmmBackward>)\n",
      "loss 2.2444987297058105\n",
      "iteration 8\n",
      "prediction tensor([[ 0.2201],\n",
      "        [ 0.5026],\n",
      "        [ 0.7850],\n",
      "        [-0.0623],\n",
      "        [ 0.2201],\n",
      "        [-1.4745],\n",
      "        [-1.5310]], grad_fn=<AddmmBackward>)\n",
      "loss 2.184845447540283\n",
      "iteration 9\n",
      "prediction tensor([[ 0.2442],\n",
      "        [ 0.5325],\n",
      "        [ 0.8207],\n",
      "        [-0.0441],\n",
      "        [ 0.2442],\n",
      "        [-1.4854],\n",
      "        [-1.5431]], grad_fn=<AddmmBackward>)\n",
      "loss 2.1274845600128174\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "losses = []\n",
    "for epoch in range(n_epoch):\n",
    "    print(\"iteration\", epoch)\n",
    "    for x, y in train_loader:\n",
    "        #print(\"x\", x)\n",
    "        #print(\"y\",y)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x)\n",
    "        print(\"prediction\", predictions)\n",
    "        loss = torch.mean((predictions - y)**2)\n",
    "        print(\"loss\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher la loss au cours de l'entraînement et vérifier qu'elle diminue bien. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.735759973526001,\n",
       " 2.656813859939575,\n",
       " 2.581012010574341,\n",
       " 2.5082154273986816,\n",
       " 2.4382898807525635,\n",
       " 2.371108293533325,\n",
       " 2.306549549102783,\n",
       " 2.2444987297058105,\n",
       " 2.184845447540283,\n",
       " 2.1274845600128174]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ca85dadcd0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les paramètres de votre régression linéaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LinearRegression(\n",
       "  (lin): Linear(in_features=1, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin.weight tensor([[0.5879]])\n",
      "lin.bias tensor([-0.3201])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
